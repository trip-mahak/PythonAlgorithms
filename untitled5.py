# -*- coding: utf-8 -*-
"""Untitled5.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/17cUiFqzzC_5YzRjDmVHB0jU6mGlnTKB7
"""

data = pd.read_excel(‘energy_data.xlsx’)
X = data[:,:4]
y = data[:,-1]

def cost_function(X, Y, B):
 m = len(Y)
 J = np.sum((X.dot(B) — Y) ** 2)/(2 * m)
 return J

def batch_gradient_descent(X, Y, B, alpha, iterations):
 cost_history = [0] * iterations
 m = len(Y)
 
 for iteration in range(iterations):
 #print(iteration)
 # Hypothesis Values
 h = X.dot(B)
 # Difference b/w Hypothesis and Actual Y
 loss = h — Y
 # Gradient Calculation
 gradient = X.T.dot(loss) / m
 # Changing Values of B using Gradient
 B = B — alpha * gradient
 # New Cost Value
 cost = cost_function(X, Y, B)
 cost_history[iteration] = cost
 
 return B, cost_history

m = 7000
f = 2
X_train = X[:m,:f]
X_train = np.c_[np.ones(len(X_train),dtype=’int64'),X_train]
y_train = y[:m]
X_test = X[m:,:f]
X_test = np.c_[np.ones(len(X_test),dtype=’int64'),X_test]
y_test = y[m:]


 # Initial Coefficients
B = np.zeros(X_train.shape[1])
alpha = 0.005
iter_ = 2000
newB, cost_history = batch_gradient_descent(X_train, y_train, B, alpha, iter_)

y_ = pred(X_test,newB)

def r2(y_,y):
 sst = np.sum((y-y.mean())**2)
 ssr = np.sum((y_-y)**2)
 r2 = 1-(ssr/sst)
 return(r2)

r2(y_,y_test)